{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Points\n",
    "\n",
    "* Created using make_moons function in sklean a synthetic dataset\n",
    "* Applied GridSearchCV with params max_leaf_nodes and max_depth\n",
    "* Used the best_estimators from GridSearch and trained 1000 separate samples of Decision Trees with each having 100 data points\n",
    "* The above model gave a validation accuracy of 78.6%\n",
    "* converted above to a a random forest by training on each test instance separately and then taking the mode amongst all predictions, and this increased validation accuracy to 86.28%\n",
    "\n",
    "|   Model       |  Validation |\n",
    "|---------------|-------------|\n",
    "| Decison Tree  |   78.64%    |\n",
    "| Random Forest |   86.28%    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data and train-test split \n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = make_moons(n_samples=10000, noise=0.4, random_state=True)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 2) (7500,)\n",
      "(2500, 2) (2500,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of classes\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def score(y, y_pred, train=False):\n",
    "    if train:\n",
    "        print(\"Training accuracy: \", accuracy_score(y, y_pred))\n",
    "    else:\n",
    "        print(\"Validation accuracy: \", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt =  DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 15 µs\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 576 out of 576 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=42,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [8, 9, 10, 11],\n",
       "                         'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training best model for later tasks\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"max_leaf_nodes\": list(range(2, 50)), \"max_depth\": list(range(8, 12))}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), verbose=1, param_grid=params, cv=3)\n",
    "%time\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "subsets = 1000\n",
    "n_instances = 100\n",
    "mini_sets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=subsets, train_size=n_instances, random_state=42)\n",
    "for mini_train_index, mini_test_index in rs.split(x_train):\n",
    "    x_mini_train = x_train[mini_train_index]\n",
    "    y_mini_train = y_train[mini_train_index]\n",
    "    mini_sets.append((x_mini_train, y_mini_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "# Created smaller subsets\n",
    "print(len(mini_sets))\n",
    "print(mini_sets[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7864703999999999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on all 1000 subsets and then evaluation of test set using each of them\n",
    "# Taken from solution as more logical way\n",
    "from sklearn.base import clone\n",
    "\n",
    "forest = [clone(grid_search.best_estimator_) for _ in range(subsets)]\n",
    "\n",
    "accuracy_ = []\n",
    "\n",
    "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
    "    tree.fit(X_mini_train, y_mini_train)\n",
    "    \n",
    "    y_pred = tree.predict(x_valid)\n",
    "    accuracy_.append(accuracy_score(y_valid, y_pred))\n",
    "\n",
    "np.mean(accuracy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Since all individual tree's in the forest have been trained above, we can directly use them to predict\n",
    "\"\"\" \n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for tree in forest:\n",
    "    ind_pred = tree.predict(x_valid)\n",
    "    y_pred.append(ind_pred)\n",
    "\n",
    "y_pred = np.asarray(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2500)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So in each row we store the 2500 predictions and we require 1 predicton for each column, means  (1, 2500)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_mode, votes = mode(y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2500)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We got the required result\n",
    "y_pred_mode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.8628\n"
     ]
    }
   ],
   "source": [
    "# This is a Random FOrest and compared to individual decision tree we got a much higher increase in accuracy\n",
    "score(y_valid, y_pred_mode.reshape(-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
