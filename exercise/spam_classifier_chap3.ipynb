{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Solution from Chapter 3 of Hands-On Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salient Points:\n",
    "\n",
    "* Uses Apache SpamAssassin's public spam-ham dataset [Link](https://homl.info/spamassassin)\n",
    "* Cleaned datasets in email-format\n",
    "* Used custom sklearn transformers for data cleaning and vectorization\n",
    "\n",
    "|   Model  | Precision | Recall |\n",
    "|----------|-----------|--------|\n",
    "| Logistic |     92%   |  96.8% |\n",
    "| Naive Bayes|   93.9% |  97.9% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Downloading the Dataset -> Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data_path = Path(\"./data/20030228_spam.tar.bz2\")\n",
    "ham_data_path = Path(\"./data/20030228_easy_ham.tar.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompression \n",
    "for path in [spam_data_path, ham_data_path]:\n",
    "    tar_obj = tarfile.open(path)\n",
    "    tar_obj.extractall(path=\"data/\")\n",
    "    tar_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spam', '20030228_spam.tar.bz2', '20030228_easy_ham.tar.bz2', 'easy_ham']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data has been decompressed\n",
    "os.listdir(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for decompressed data\n",
    "spam_path = Path(\"./data/spam/\")\n",
    "ham_path = Path(\"./data/easy_ham/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all spam and ham files\n",
    "spam_files = [spam_path/file for file in os.listdir(spam_path)  if file != 'cmds']\n",
    "ham_files = [ham_path/file for file in os.listdir(ham_path)  if file != 'cmds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/spam/00075.28a918cd03a0ef5aa2f1e0551a798108'), PosixPath('data/spam/00376.f4ed5f002f9b6b320a67f1da9cacbe72'), PosixPath('data/spam/00029.de865ad8d5ad0df985ae2f72388befba'), PosixPath('data/spam/00192.e5a6bb15ae1e965f3b823c75e435651a'), PosixPath('data/spam/00409.e59f63e813b6766a9a4ddf0790634ca3')]\n",
      "[PosixPath('data/easy_ham/01263.40cec40ea12c55f2ac9a98dc07c55d1c'), PosixPath('data/easy_ham/00238.dab1868a3b43de1e01ebdfd0e53de50f'), PosixPath('data/easy_ham/00088.945614c3f6213f59548ab21306451675'), PosixPath('data/easy_ham/02051.58e196144807bd76d7b77d4b7efb6d32'), PosixPath('data/easy_ham/01232.2f44f5a2186e97cf4d65cf191d98e646')]\n"
     ]
    }
   ],
   "source": [
    "print(spam_files[:5])\n",
    "print(ham_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_files), len(ham_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From iiu-owner@taint.org  Mon Aug 26 15:48:26 2002\n",
      "Return-Path: <iiu-owner@taint.org>\n",
      "Delivered-To: zzzz@localhost.spamassassin.taint.org\n",
      "Received: from localhost (localhost [127.0.0.1])\n",
      "\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 35D3247C86\n",
      "\tfor <zzzz@localhost>; Mon, 26 Aug 2002 10:41:37 -0400 (EDT)\n",
      "Received: from phobos [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor zzzz@localhost (single-drop); Mon, 26 Aug 2002 15:41:37 +0100 (IST)\n",
      "Received: from dogma.slashnull.org (localhost [127.0.0.1]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7NIi2Z03983 for\n",
      "    <zzzz-list-admin-iiu@jmason.org>; Fri, 23 Aug 2002 19:44:02 +0100\n",
      "Received: from linux.local ([213.9.245.86]) by dogma.slashnull.org\n",
      "    (8.11.6/8.11.6) with SMTP id g7NIh1Z03950 for <iiu-admin@taint.org>;\n",
      "    Fri, 23 Aug 2002 19:43:02 +0100\n",
      "Message-Id: <200208231843.g7NIh1Z03950@dogma.slashnull.org>\n",
      "Received: (qmail 28875 invoked from network); 23 Aug 2002 18:18:58 -0000\n",
      "Received: from unknown (HELO h) (192.168.0.2) by linux.local with SMTP;\n",
      "    23 Aug 2002 18:18:58 -0000\n",
      "From: \"Sales Department\" <info@cheapsmoking.com>\n",
      "Subject: Low Price Smokes\n",
      "To: iiu-admin@taint.org\n",
      "Reply-To: info@cheapsmoking.com\n",
      "Date: Fri, 23 Aug 2002 20:24:48 +0200\n",
      "X-Priority: 3\n",
      "X-Library: Indy 8.0.25\n",
      "Sender: iiu-owner@taint.org\n",
      "Errors-To: iiu-owner@taint.org\n",
      "X-Beenthere: iiu@iiu.taint.org\n",
      "X-Mailman-Version: 2.0.10\n",
      "Precedence: bulk\n",
      "List-Unsubscribe: <http://iiu.taint.org/mailman/listinfo/iiu>,\n",
      "    <mailto:iiu-request@iiu.taint.org?subject=unsubscribe>\n",
      "List-Id: Irish Internet Users <iiu.iiu.taint.org>\n",
      "List-Post: <mailto:iiu@iiu.taint.org>\n",
      "List-Help: <mailto:iiu-request@iiu.taint.org?subject=help>\n",
      "List-Subscribe: <http://iiu.taint.org/mailman/listinfo/iiu>,\n",
      "    <mailto:iiu-request@iiu.taint.org?subject=subscribe>\n",
      "List-Archive: <http://iiu.taint.org/pipermail/iiu/>\n",
      "\n",
      "Dear Sir / Madam\n",
      "\n",
      "If you are fed up of being 'ripped off' by the British government every time you buy your tobacco, then you should visit our website, where you can now buy 4 cartons of cigarettes, or 40 pouches of rolling tobacco from as little as 170 Euros (approx 105 pounds), inclusive of delivery by registered air mail from our office in Spain.  \n",
      "\n",
      "Why pay more???\n",
      "\n",
      "Visit our website at\n",
      "http://www.cheapsmoking.com/?ID=2\n",
      "\n",
      "Best regards\n",
      "Sales Department\n",
      "Cheap Smoking\n",
      "Spain\n",
      "xay1992361y\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# File format -> Email format\n",
    "f = open(spam_files[0])\n",
    "content = f.read()\n",
    "f.close()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using python's email library as it makes parsing easy\n",
    "# https://docs.python.org/3/library/email.examples.html\n",
    "from email import policy\n",
    "from email.parser import BytesParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_loader(filenames):\n",
    "    parsed_email = []\n",
    "    for file in filenames:\n",
    "        with open(file, 'rb') as fp:\n",
    "            parsed_email.append(BytesParser(policy=policy.default).parse(fp))\n",
    "    return parsed_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_email = email_loader(spam_files)\n",
    "ham_email = email_loader(ham_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Return-Path', '<iiu-owner@taint.org>'), ('Delivered-To', 'zzzz@localhost.spamassassin.taint.org'), ('Received', 'from localhost (localhost [127.0.0.1])\\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 35D3247C86\\tfor <zzzz@localhost>; Mon, 26 Aug 2002 10:41:37 -0400 (EDT)'), ('Received', 'from phobos [127.0.0.1]\\tby localhost with IMAP (fetchmail-5.9.0)\\tfor zzzz@localhost (single-drop); Mon, 26 Aug 2002 15:41:37 +0100 (IST)'), ('Received', 'from dogma.slashnull.org (localhost [127.0.0.1]) by    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7NIi2Z03983 for    <zzzz-list-admin-iiu@jmason.org>; Fri, 23 Aug 2002 19:44:02 +0100'), ('Received', 'from linux.local ([213.9.245.86]) by dogma.slashnull.org    (8.11.6/8.11.6) with SMTP id g7NIh1Z03950 for <iiu-admin@taint.org>;    Fri, 23 Aug 2002 19:43:02 +0100'), ('Message-Id', '<200208231843.g7NIh1Z03950@dogma.slashnull.org>'), ('Received', '(qmail 28875 invoked from network); 23 Aug 2002 18:18:58 -0000'), ('Received', 'from unknown (HELO h) (192.168.0.2) by linux.local with SMTP;    23 Aug 2002 18:18:58 -0000'), ('From', 'Sales Department <info@cheapsmoking.com>'), ('Subject', 'Low Price Smokes'), ('To', 'iiu-admin@taint.org'), ('Reply-To', 'info@cheapsmoking.com'), ('Date', 'Fri, 23 Aug 2002 20:24:48 +0200'), ('X-Priority', '3'), ('X-Library', 'Indy 8.0.25'), ('Sender', 'iiu-owner@taint.org'), ('Errors-To', 'iiu-owner@taint.org'), ('X-Beenthere', 'iiu@iiu.taint.org'), ('X-Mailman-Version', '2.0.10'), ('Precedence', 'bulk'), ('List-Unsubscribe', '<http://iiu.taint.org/mailman/listinfo/iiu>,    <mailto:iiu-request@iiu.taint.org?subject=unsubscribe>'), ('List-Id', 'Irish Internet Users <iiu.iiu.taint.org>'), ('List-Post', '<mailto:iiu@iiu.taint.org>'), ('List-Help', '<mailto:iiu-request@iiu.taint.org?subject=help>'), ('List-Subscribe', '<http://iiu.taint.org/mailman/listinfo/iiu>,    <mailto:iiu-request@iiu.taint.org?subject=subscribe>'), ('List-Archive', '<http://iiu.taint.org/pipermail/iiu/>')]\n",
      "Dear Sir / Madam\n",
      "\n",
      "If you are fed up of being 'ripped off' by the British government every time you buy your tobacco, then you should visit our website, where you can now buy 4 cartons of cigarettes, or 40 pouches of rolling tobacco from as little as 170 Euros (approx 105 pounds), inclusive of delivery by registered air mail from our office in Spain.  \n",
      "\n",
      "Why pay more???\n",
      "\n",
      "Visit our website at\n",
      "http://www.cheapsmoking.com/?ID=2\n",
      "\n",
      "Best regards\n",
      "Sales Department\n",
      "Cheap Smoking\n",
      "Spain\n",
      "xay1992361y\n"
     ]
    }
   ],
   "source": [
    "# Same as above, can be accessed as key value pairs\n",
    "print(spam_email[0].items())\n",
    "print(spam_email[0].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <evtwqmigru@datcon.co.uk>\n",
      "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
      "Received : from localhost (jalapeno [127.0.0.1])\tby zzzzason.org (Postfix) with ESMTP id F3CF116F1B\tfor <zzzz@localhost>; Tue,  8 Oct 2002 11:02:13 +0100 (IST)\n",
      "Received : from jalapeno [127.0.0.1]\tby localhost with IMAP (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Tue, 08 Oct 2002 11:02:13 +0100 (IST)\n",
      "Received : from webnote.net (mail.webnote.net [193.120.211.219]) by    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g989wGK10152 for    <zzzz@jmason.org>; Tue, 8 Oct 2002 10:58:16 +0100\n",
      "Received : from sanaga.camtel.cm ([195.24.194.61]) by webnote.net    (8.9.3/8.9.3) with ESMTP id KAA21887 for <zzzz@spamassassin.taint.org>;    Tue, 8 Oct 2002 10:59:00 +0100\n",
      "Received : from ens.fr (host42-226.pool8173.interbusiness.it    [81.73.226.42]) by sanaga.camtel.cm with SMTP (Microsoft Exchange Internet    Mail Service Version 5.5.1960.3) id 431SJ0H6; Tue, 8 Oct 2002 06:55:54    -0000\n",
      "Message-Id : <00004b14417b$0000234d$000007e2@cuug.ab.ca>\n",
      "To : wciml@chez.com\n",
      "From : About Time <evtwqmigru@datcon.co.uk>\n",
      "Subject : Faeries\n",
      "Date : Wed, 07 Oct 2020 23:01:36 -1900\n",
      "MIME-Version : 1.0\n",
      "Content-Type : text/plain; charset=\"Windows-1252\"\n",
      "Content-Transfer-Encoding : 7bit\n",
      "Reply-To : evtwqmigru@datcon.co.uk\n"
     ]
    }
   ],
   "source": [
    "# Checking the headers and items for the files\n",
    "for key, val in zip(spam_email[23].keys(), spam_email[23].values()):\n",
    "    print(\"{} : {}\".format(key, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Content-Type` varies across the different emails and so we need to use Beautiful Soup to properly extract the content from them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text/plain; charset=\"Windows-1252\"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(spam_email[23].items())['Content-Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def email_content_type(emails):\n",
    "    content_type = Counter()\n",
    "    for email in emails:\n",
    "        content_type[email.get_content_type()] += 1\n",
    "    return content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'text/plain': 2408, 'multipart/signed': 68, 'multipart/mixed': 10, 'multipart/alternative': 9, 'multipart/related': 3, 'multipart/report': 2})\n",
      "Counter({'text/plain': 218, 'text/html': 183, 'multipart/alternative': 47, 'multipart/mixed': 43, 'multipart/related': 9})\n"
     ]
    }
   ],
   "source": [
    "print(email_content_type(ham_email))\n",
    "print(email_content_type(spam_email))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8593; shows that spam email has a smaller proportion of data in plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a good way of getting the content structures as this gives\n",
    "# a more detailed output (From solutions)\n",
    "\n",
    "\n",
    "# def get_email_structure(email):\n",
    "#     if isinstance(email, str):\n",
    "#         return email\n",
    "#     payload = email.get_payload()\n",
    "#     if isinstance(payload, list):\n",
    "#         return \"multipart({})\".format(\", \".join([\n",
    "#             get_email_structure(sub_email)\n",
    "#             for sub_email in payload\n",
    "#         ]))\n",
    "#     else:\n",
    "#         return email.get_content_type()\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "# def structures_counter(emails):\n",
    "#     structures = Counter()\n",
    "#     for email in emails:\n",
    "#         structure = get_email_structure(email)\n",
    "#         structures[structure] += 1\n",
    "#     return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.debugger import set_trace\n",
    "# https://stackoverflow.com/questions/328356/extracting-text-from-html-file-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_(email):\n",
    "    clean_text=\"\"\n",
    "    if len(email.get_payload()) > 100:\n",
    "            clean_text = ''.join(BeautifulSoup\n",
    "                (email.get_payload(), \"html.parser\").stripped_strings)\n",
    "    else:\n",
    "        for submail in email.get_payload():\n",
    "            if submail.get_content_type() in ('multipart/alternative', 'multipart/related', 'multipart/mixed', 'multipart/report', 'multipart/signed'):\n",
    "                clean_text += multi_(submail)\n",
    "            elif submail.get_content_type() in (\"application/octet-stream\", \"image/jpeg\", \"image/gif\"):\n",
    "                clean_text += submail.get_content_type()\n",
    "            elif submail.get_content_type() in (\"text/plain\", \"text/html\"):\n",
    "                clean_text += ''.join(BeautifulSoup\n",
    "                    (submail.get_payload(), \"html.parser\").stripped_strings)\n",
    "            else: continue\n",
    "    return clean_text\n",
    "\n",
    "def html2text(emails):\n",
    "    data = []\n",
    "    for email in emails:\n",
    "        if email.get_content_type() in (\"text/plain\", \"text/html\") or len(email.get_payload()) > 100:\n",
    "            clean_text = ''.join(BeautifulSoup\n",
    "                (email.get_payload(), \"html.parser\").stripped_strings)\n",
    "        elif email.get_content_type() in ('multipart/alternative', 'multipart/related', 'multipart/mixed', 'multipart/report', 'multipart/signed'):\n",
    "            clean_text = multi_(email)\n",
    "        else:\n",
    "            clean_text = \"\"\n",
    "            for submail in email.get_payload():\n",
    "                clean_text += ''.join(BeautifulSoup\n",
    "                (submail.get_payload(), \"html.parser\").stripped_strings)\n",
    "        data.append(clean_text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spam_clean = html2text(spam_email)\n",
    "all_ham_clean = html2text(ham_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(all_ham_clean + all_spam_clean)\n",
    "y = np.array([0] * len(all_ham_clean) + [1] * len(all_spam_clean))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Custom Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from collections import Counter\n",
    "import urlextract #Taken from sols as regex approach was not great\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "url_extractor = urlextract.URLExtract()\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "class data_prep(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lowercase=True, punctuation=True, urls=True, \n",
    "                numbers=True, stemming=True):\n",
    "        self.lowercase = lowercase\n",
    "        self.punctuation = punctuation\n",
    "        self.urls = urls\n",
    "        self.numbers = numbers\n",
    "        self.stemming = True\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        data = []\n",
    "        for text in X:\n",
    "            if self.lowercase:\n",
    "                text = text.lower()\n",
    "            if self.urls:\n",
    "                ext_urls = list(set(url_extractor.find_urls(text)))\n",
    "                ext_urls.sort(key=lambda x: len(x), reverse=True)\n",
    "                for url in ext_urls:\n",
    "                    text = text.replace(url, \"URL\")\n",
    "            if self.punctuation:\n",
    "                text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "#           # From solution\n",
    "            if self.numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "            words = Counter(text.split())\n",
    "            if self.stemming:\n",
    "                word_stemmed = Counter()\n",
    "                for word, count in words.items():\n",
    "                    word_stemmed[stemmer.stem(word)] += count\n",
    "                words = word_stemmed\n",
    "            data.append(words)\n",
    "        return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'number': 6, 'url': 3, 'date': 1, 'numbertnumb': 1}),\n",
       "       Counter({'to': 10, 'the': 6, 'url': 5, 'in': 5, 'line': 4, 'i': 4, 'it': 4, 'a': 4, 'mail': 4, 'list': 4, 'm': 3, 'sa': 3, 'and': 3, 'spamassassin': 3, 'user_pref': 3, 'is': 3, 'be': 3, 'have': 2, 'get': 2, 'work': 2, 'like': 2, 'on': 2, 'if': 2, 'user': 2, 'ha': 2, 'file': 2, 'doe': 2, 'that': 2, 'all': 2, 'against': 2, 'ani': 2, 'still': 2, 'here': 2, 'their': 2, 'of': 2, 'for': 2, 'net': 2, 'talk': 2, 'as': 1, 'subject': 1, 'indic': 1, 'sure': 1, 'these': 1, 'are': 1, 'stupid': 1, 'question': 1, 'but': 1, 'troubl': 1, 'understand': 1, 'should': 1, 'about': 1, 'given': 1, 'up': 1, 'tri': 1, 'figur': 1, 'out': 1, 'myself': 1, 'whitelist_from': 1, 'hi': 1, 'not': 1, 'effect': 1, 'tell': 1, 'program': 1, 'take': 1, 'no': 1, 'action': 1, 'at': 1, 'come': 1, 'from': 1, 'or': 1, 'there': 1, 'check': 1, 'done': 1, 'latter': 1, 'what': 1, 'he': 1, 'need': 1, 'place': 1, 'caus': 1, 'such': 1, 'ignor': 1, 'test': 1, 'with': 1, 'few': 1, 'who': 1, 'happen': 1, 'yahoogroup': 1, 'befor': 1, 'deploy': 1, 'system': 1, 'wide': 1, 'although': 1, 'abov': 1, 'been': 1, 'ad': 1, 'much': 1, 'go': 1, 'spam': 1, 'folder': 1, 'due': 1, 'usual': 1, 'thing': 1, 'you': 1, 'would': 1, 'expect': 1, 'trigger': 1, 'thank': 1, 'advanc': 1, 'help': 1, 'ken': 1, 'scott': 1, 'admin': 1, 'shellworld': 1, 'thi': 1, 'email': 1, 'sponsor': 1, 'by': 1, 'osdn': 1, 'tire': 1, 'same': 1, 'old': 1, 'cell': 1, 'phone': 1, 'new': 1, 'free': 1, '_______________________________________________': 1, 'sourceforg': 1}),\n",
       "       Counter({'the': 50, 'to': 35, 'a': 21, 'of': 21, 'that': 18, 'and': 17, 'law': 12, 'in': 12, 'internet': 11, 'for': 11, 'is': 9, 'it': 9, 'number': 9, 'propos': 9, 'provid': 9, 'canadian': 8, 'be': 8, 'polic': 7, 'treati': 7, 'are': 6, 'canada': 6, 'say': 6, 'cybercrim': 6, 'have': 6, 'govern': 5, 's': 5, 'would': 5, 'all': 5, 'you': 4, 'anonym': 4, 'their': 4, 'nation': 4, 'databas': 4, 'with': 4, 'enforc': 4, 'electron': 4, 'chang': 4, 'said': 4, 'not': 4, 'privaci': 4, 'also': 3, 'i': 3, 'about': 3, 'from': 3, 'by': 3, 'agenc': 3, 'discuss': 3, 'an': 3, 'right': 3, 'blueprint': 3, 'more': 3, 'author': 3, 'on': 3, 'draft': 3, 'or': 3, 'such': 3, 'if': 3, 'order': 3, 'allow': 3, 'requir': 3, 'ha': 3, 'onli': 3, 'geist': 3, 'at': 3, 'need': 3, 'there': 3, 'new': 3, 'power': 3, 'compani': 3, 'servic': 3, 'inform': 3, 'what': 2, 'place': 2, 'thi': 2, 'stori': 2, 'ottawa': 2, 'just': 2, 'offic': 2, 'militari': 2, 'will': 2, 'becom': 2, 'spi': 2, 'url': 2, 'consid': 2, 'network': 2, 'surveil': 2, 'contempl': 2, 'as': 2, 'process': 2, 'agent': 2, 'conduct': 2, 'commun': 2, 'run': 2, 'they': 2, 'council': 2, 'europ': 2, 'which': 2, 'countri': 2, 'comput': 2, 'most': 2, 'unit': 2, 'state': 2, 'repres': 2, 'activist': 2, 'adopt': 2, 'ratifi': 2, 'who': 2, 'special': 2, 'justif': 2, 'sweep': 2, 'seem': 2, 'me': 2, 'we': 2, 'make': 2, 'case': 2, 'compel': 2, 'data': 2, 'call': 2, 'capabl': 2, 'andrew': 2, 'epic': 2, 'intern': 2, 'doe': 2, 'hosein': 2, 're': 2, 'comment': 2, 'politician': 1, 'worldwid': 1, 'discov': 1, 'great': 1, 'tool': 1, 'fascism': 1, 'onc': 1, 'got': 1, 'solv': 1, 'whole': 1, 'thing': 1, 'notic': 1, 'show': 1, 'truth': 1, 'realli': 1, 'locat': 1, 'washington': 1, 'dc': 1, 'branch': 1, 'come': 1, 'think': 1, 'last': 1, 'post': 1, 'featur': 1, 'head': 1, 'speak': 1, 'us': 1, 'hq': 1, 'palm': 1, 'beach': 1, 'florida': 1, 'owen': 1, 'isp': 1, 'declan': 1, 'mccullaghstaff': 1, 'writer': 1, 'cnet': 1, 'august': 1, 'pm': 1, 'pt': 1, 'forc': 1, 'rewir': 1, 'easi': 1, 'draftreleas': 1, 'sunday': 1, 'creat': 1, 'everi': 1, 'account': 1, 'plan': 1, 'could': 1, 'sharpli': 1, 'curtail': 1, 'onlin': 1, 'includ': 1, 'depart': 1, 'justiceand': 1, 'industri': 1, 'wrote': 1, 'page': 1, 'near': 1, 'final': 1, 'step': 1, 'seek': 1, 'give': 1, 'base': 1, 'expect': 1, 'introduc': 1, 'parliament': 1, 'late': 1, 'year': 1, 'earli': 1, 'argu': 1, 'take': 1, 'form': 1, 'offici': 1, 'necessari': 1, 'fight': 1, 'terror': 1, 'combat': 1, 'even': 1, 'mill': 1, 'crime': 1, 'claim': 1, 'enact': 1, 'these': 1, 'follow': 1, 'oblig': 1, 'under': 1, 'were': 1, 'outlaw': 1, 'possess': 1, 'virus': 1, 'retain': 1, 'log': 1, 'web': 1, 'brows': 1, 'up': 1, 'six': 1, 'month': 1, 'permit': 1, 'obtain': 1, 'search': 1, 'warrant': 1, 'them': 1, 'find': 1, 'hidden': 1, 'digit': 1, 'devic': 1, 'suspect': 1, 'might': 1, 'conceal': 1, 'circumst': 1, 'court': 1, 'monitor': 1, 'nonvot': 1, 'member': 1, 'both': 1, 'endors': 1, 'controversi': 1, 'drawn': 1, 'protest': 1, 'human': 1, 'civil': 1, 'liberti': 1, 'group': 1, 'nearli': 1, 'particip': 1, 'albania': 1, 'formal': 1, 'michael': 1, 'professor': 1, 'univers': 1, 'e': 1, 'commerc': 1, 'weak': 1, 'main': 1, 've': 1, 'given': 1, 'want': 1, 'particularli': 1, 'convinc': 1, 'argument': 1, 'ad': 1, 'noth': 1, 'document': 1, 'indic': 1, 'don': 1, 't': 1, 'know': 1, 'been': 1, 'signific': 1, 'where': 1, 'into': 1, 'problem': 1, 'probabl': 1, 'legal': 1, 'telephon': 1, 'reconfigur': 1, 'facilit': 1, 'eavesdrop': 1, 'retent': 1, 'similar': 1, 'assist': 1, 'act': 1, 'but': 1, 'appli': 1, 'pre': 1, 'telecommun': 1, 'wireless': 1, 'wirelin': 1, 'ensur': 1, 'system': 1, 'technic': 1, 'access': 1, 'secur': 1, 'accord': 1, 'respons': 1, 'pay': 1, 'cost': 1, 'buy': 1, 'equip': 1, 'sarah': 1, 'analyst': 1, 'center': 1, 'goe': 1, 'beyond': 1, 'specifi': 1, 'intercept': 1, 'talk': 1, 'deal': 1, 'opposesth': 1, 'grant': 1, 'too': 1, 'much': 1, 'adequ': 1, 'respect': 1, 'anoth': 1, 'section': 1, 'associ': 1, 'chief': 1, 'recommend': 1, 'establish': 1, 'person': 1, 'user': 1, 'implement': 1, 'presuppos': 1, 'accur': 1, 'current': 1, 'gu': 1, 'visit': 1, 'fellow': 1, 'london': 1, 'school': 1, 'econom': 1, 'dumb': 1, 'idea': 1, 'immedi': 1, 'wonder': 1, 'use': 1, 'mobil': 1, 'phone': 1, 'whether': 1, 'connect': 1, 'georg': 1, 'radwanski': 1, 'commission': 1, 'review': 1, 'ani': 1, 'paper': 1, 'stand': 1, 'can': 1, 'sent': 1, 'la': 1, 'al': 1, 'justic': 1, 'gc': 1, 'cano': 1, 'later': 1, 'than': 1, 'nov': 1}),\n",
       "       Counter({'number': 418, 'check': 51, 'sep': 47, 'razor': 28, 'url': 21, 'mail': 16, 'server': 13, 'root': 12, 'from': 11, 'to': 11, 'a': 9, 'spam': 8, 'comput': 7, 'read': 7, 'sig': 7, 'not': 6, 'log': 5, 'found': 5, 'conf': 5, 'default': 5, 'read_fil': 5, 'item': 5, 'sampl': 4, 'txt': 4, 'd': 4, 'agent': 4, 'assign': 4, 'is': 4, 'srl': 4, 'e': 4, 'use': 3, 'spamassassin': 3, 'i': 3, 's': 3, 'user': 3, 'razorhom': 3, 'no': 3, 'supported_engin': 3, 'lst': 3, 'catalogu': 3, 'c': 3, 'pgffftenumberpnumberv': 3, 'cptdunumbernwgibika': 3, 'knumberogzsanumberavvolyvalwxnumberaacdwbnumbera': 3, 'the': 2, 'and': 2, 'ani': 2, 'maxwel': 2, 'usr': 2, 'src': 2, 'skip': 2, 'ident': 2, 'freebsd': 2, 'releas': 2, 'pnumber': 2, 'whitelist': 2, 'discoveri': 2, 'closest': 2, 'min_cf': 2, 'se': 2, 'numbera': 2, 'for': 2, 'connect': 2, 'epnumb': 2, 'enumb': 2, 'p': 2, 'method': 2, 'content': 2, 'part': 2, 'net': 2, 'list': 2, 'on': 1, 'tue': 1, 'rose': 1, 'bobbi': 1, 'wrote': 1, 'do': 1, 'interest': 1, 'just': 1, 'upgrad': 1, 'yesterday': 1, 'ran': 1, 'admin': 1, 'regist': 1, 'am': 1, 'see': 1, 'that': 1, 'm': 1, 'get': 1, 'posit': 1, 'includ': 1, 'suggest': 1, 'thank': 1, 'output': 1, 'below': 1, 'var': 1, 'qmail': 1, 'alia': 1, 'gb': 1, 'local': 1, 'env': 1, 'bootup': 1, 'initi': 1, 'logdebuglevel': 1, 'stdout': 1, 'ruqvanumberjbu': 1, 'vnumber': 1, 'start': 1, 'unam': 1, 'wed': 1, 'may': 1, 'edt': 1, 'sy': 1, 'compil': 1, 'inumb': 1, 'straight': 1, 'rfcnumber': 1, 'fromsep': 1, 'client': 1, 'prep_mail': 1, 'done': 1, 'header': 1, 'mimenumb': 1, 'file': 1, 'empti': 1, 'nomin': 1, 'second': 1, 'befor': 1, 'next': 1, 'cach': 1, 'info': 1, 'subject': 1, 'home': 1, 'base': 1, 'busi': 1, 'grownup': 1, 'preproc': 1, 'went': 1, 'byte': 1, 'len': 1, 'establish': 1, 'greet': 1, 'sn': 1, 'l': 1, 'prepar': 1, 'queri': 1, 'send': 1, 'batch': 1, 'respons': 1, 'sent': 1, 'non': 1, 'known': 1, 'disconnect': 1, 'q': 1, 'finish': 1, 'success': 1, 'david': 1, 'raistrick': 1, 'drai': 1, 'atlasta': 1, 'thi': 1, 'email': 1, 'sponsor': 1, 'by': 1, 'thinkgeek': 1, 'welcom': 1, 'geek': 1, 'heaven': 1, '_______________________________________________': 1, 'sourceforg': 1}),\n",
       "       Counter({'your': 12, 'number': 9, 'you': 6, 'to': 6, 'and': 6, 'thi': 4, 'of': 3, 'comput': 3, 'from': 3, 'for': 3, 'email': 3, 'in': 3, 'list': 3, 'norton': 2, 'take': 2, 'control': 2, 'the': 2, 'softwar': 2, 'pack': 2, 'protect': 2, 'valuabl': 2, 'inform': 2, 'pc': 2, 'have': 2, 'ani': 2, 'or': 2, 'here': 2, 'opt': 2, 'spam': 2, 'if': 2, 'unsubscrib': 2, 'ad': 1, 'with': 1, 'top': 1, 'line': 1, 'td': 1, 'systemwork': 1, 'numbersoftwar': 1, 'suit': 1, 'profession': 1, 'edit': 1, 'includ': 1, 'six': 1, 'ye': 1, 'featur': 1, 'utilitiesal': 1, 'fornumberspeciallowpric': 1, 'ofonli': 1, 'will': 1, 'unwant': 1, 'andhazardousvir': 1, 'use': 1, 'help': 1, 'secur': 1, 'privat': 1, 'allow': 1, 'transfer': 1, 'file': 1, 'send': 1, 'e': 1, 'mailssaf': 1, 'backup': 1, 'all': 1, 'data': 1, 'quick': 1, 'easili': 1, 'improv': 1, 's': 1, 'perform': 1, 'w': 1, 'superiorintegr': 1, 'diagnost': 1, 'll': 1, 'never': 1, 'repair': 1, 'shop': 1, 'again': 1, 'numberfeatur': 1, 'utilitiesnumbergreat': 1, 'pricea': 1, 'combin': 1, 'retail': 1, 'valueyoursfor': 1, 'onli': 1, 'price': 1, 'includesfreeship': 1, 'a': 1, 'limit': 1, 'time': 1, 'buy': 1, 'our': 1, 'product': 1, 'get': 1, 'free': 1, 'don': 1, 't': 1, 'fall': 1, 'prey': 1, 'destruct': 1, 'virus': 1, 'hacker': 1, 'click': 1, 'order': 1, 'now': 1, 'address': 1, 'wa': 1, 'obtain': 1, 'an': 1, 'uefa': 1, 'unit': 1, 'feder': 1, 'against': 1, 'approv': 1, 'purchas': 1, 'code': 1, 'wish': 1, 'be': 1, 'pleaseclick': 1, 'previous': 1, 'are': 1, 'still': 1, 'receivi': 1, 'ng': 1, 'messag': 1, 'may': 1, 'ourspam': 1, 'abus': 1, 'center': 1, 'we': 1, 'do': 1, 'not': 1, 'condon': 1, 'shape': 1, 'm': 1, 'thank': 1, 'kindli': 1, 'cooper': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Its working\n",
    "data_prep().fit_transform(x_test[5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From solutions\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class vectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocab_size = 1000):\n",
    "        self.vocab_size = vocab_size\n",
    "    def fit(self, x, y=None):\n",
    "        total_words = Counter()\n",
    "        for text in x:\n",
    "            for word, count in text.items():\n",
    "                total_words[word] += count\n",
    "        most_common = total_words.most_common()[:self.vocab_size]\n",
    "        self.most_common = most_common\n",
    "        self.vocabulary_ = {word:index+1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, x, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for index, text in enumerate(x):\n",
    "            for word, count in text.items():\n",
    "                rows.append(index)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(x), self.vocab_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x21 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 65 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer(vocab_size=20).fit_transform(data_prep().fit_transform(x_test[5:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data_preprocess_pipe = Pipeline([\n",
    "    (\"text_clean\", data_prep()),\n",
    "    (\"text_vectorizer\", vectorizer()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_trans = data_preprocess_pipe.fit_transform(x_train)\n",
    "x_test_trans = data_preprocess_pipe.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  5,  6, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How the transformed data in vectorized form looks\n",
    "x_train_trans[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "log = LogisticRegression(random_state=42)\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_test, y_pred):\n",
    "    print(\"Precision: {:.1f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "    print(\"Recall: {:.1f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 92.0%\n",
      "Recall: 96.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hellraizer/tf2/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log.fit(x_train_trans, y_train)\n",
    "\n",
    "y_pred = log.predict(x_test_trans)\n",
    "score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 93.9%\n",
      "Recall: 97.9%\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "mnb.fit(x_train_trans, y_train)\n",
    "\n",
    "y_pred = mnb.predict(x_test_trans)\n",
    "score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
